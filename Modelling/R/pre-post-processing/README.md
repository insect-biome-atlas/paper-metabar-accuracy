# TreePPL Abundance Estimates - supporting functions in R

**Project**: Metabarcoding abundance estimation using TreePPL probabilistic programming  
**Author**: Emma  
**Last Updated**: February 2026

---

## ğŸ“‹ OVERVIEW

This repository contains a complete R pipeline for:
1. **Training** Bayesian models via MCMC in TreePPL
2. **Validating** convergence and model quality
3. **Predicting** species abundance from metabarcoding data
4. **Processing** prediction outputs for downstream analysis

**Total Files**: 11 production-ready R scripts organized in 2 main pipelines

---

## ğŸ—‚ï¸ REPOSITORY STRUCTURE

```
.
â”œâ”€â”€ README.md                                    # This file - Master overview
â”œâ”€â”€ README_MCMC_TRAINING.md                      # Pipeline 1: Training & postprocessing
â”œâ”€â”€ README_STITCHING.md                          # Pipeline 2: Prediction processing
â”‚
â”œâ”€â”€ MCMC_TRAINING_PIPELINE/
â”‚   â”œâ”€â”€ mcmc_convergence.R                       # Core: Convergence diagnostics
â”‚   â”œâ”€â”€ run_mcmc_convergence.R                   # Runner: Batch convergence checks
â”‚   â”œâ”€â”€ postprocessing_after_mcmc.R              # Core: MCMC â†’ prediction transform
â”‚   â”œâ”€â”€ run_postprocessing_after_mcmc.R          # Runner: Batch postprocessing
â”‚   â””â”€â”€ create_species_mapping.R                 # Utility: Species ID mapping
â”‚
â”œâ”€â”€ PREDICTION_STITCHING_PIPELINE/
â”‚   â”œâ”€â”€ stitch_simple_n_models_spikeins.R        # Core: Stitch simple models
â”‚   â”œâ”€â”€ stitch_match_models_spikeins.R           # Core: Stitch match models
â”‚   â”œâ”€â”€ stitch_predictions_fullset.R             # Core: Stitch with QC (advanced)
â”‚   â”œâ”€â”€ run_stitcher_spikeins.r                  # Runner: Batch spike-in stitching
â”‚   â””â”€â”€ run_stitcher_fullset.r                   # Runner: Full dataset stitching
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ species_map.csv                          # Species ID â†’ name mapping
    â”œâ”€â”€ cleaned_nochimera_MATCHED_cluster_counts_*.csv
    â””â”€â”€ species_map_diagnostics/                 # Validation outputs
```

---

## ğŸ”„ COMPLETE WORKFLOW

### The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TreePPL MCMC  â”‚  Run Bayesian MCMC training
â”‚   (3+ chains)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PIPELINE 1: MCMC TRAINING & POSTPROCESSING     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Check convergence (R-hat, ESS, Geweke)      â”‚
â”‚  2. Validate all chains converged               â”‚
â”‚  3. Transform samples for prediction            â”‚
â”‚  4. Generate prediction input JSONs             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TreePPL Predict â”‚  Run predictions on test data
â”‚ (per species)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PIPELINE 2: PREDICTION STITCHING              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Create species mapping                      â”‚
â”‚  2. Stitch NDJSON outputs                       â”‚
â”‚  3. Validate data quality                       â”‚
â”‚  4. Generate RDS for analysis                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analysis/Plots  â”‚  Downstream analysis & visualization
â”‚  (Separate)     â”‚  (Plotting functions in separate folder)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ QUICK START GUIDE

### Prerequisites

```r
# Install required packages
install.packages(c(
  "jsonlite", "dplyr", "tidyr", "stringr", "purrr", 
  "tibble", "coda", "ggplot2", "readr"
))
```

### Step-by-Step Workflow

#### **Stage 1: MCMC Training** (After TreePPL MCMC runs)

```r
# 1. Check convergence for all models
source("MCMC_TRAINING_PIPELINE/run_mcmc_convergence.R")
# â†’ Creates mcmc_check_*/ directories with diagnostics

# 2. Review convergence
# Check mcmc_check_biospikeins/convergence_summary.csv (and others)
# Ensure all parameters show "converged" verdict

# 3. Postprocess MCMC outputs
source("MCMC_TRAINING_PIPELINE/run_postprocessing_after_mcmc.R")
# â†’ Creates pred_in_*.json files for TreePPL prediction step
```

**Outputs**: 5 JSON files ready for prediction (art, bio, comb, 6k, 8k)

---

#### **Stage 2: Prediction Processing** (After TreePPL predictions)

**Option A: Spike-in Validation**

```r
# 1. Stitch all spike-in validation models
source("PREDICTION_STITCHING_PIPELINE/run_stitcher_spikeins.r")
# â†’ Creates stitched_pred_spikeins_*.rds files

# 2. Ready for plotting/analysis (use plotting pipeline)
```

**Option B: Full Dataset with QC**

```r
# 1. Create species mapping
source("PREDICTION_STITCHING_PIPELINE/create_species_mapping.R")
# â†’ Creates data/species_map.csv + diagnostics

# 2. Review mapping diagnostics
# Check data/species_map_diagnostics/*.csv for mismatches

# 3. Stitch predictions with quality control
source("PREDICTION_STITCHING_PIPELINE/stitch_predictions_fullset.R")
# â†’ Creates stitched_pred_fullset.rds + QC diagnostics

# 4. Review stitching diagnostics
# Check diag_sweeps.csv, diag_species_lengths.csv, etc.

# 5. Ready for analysis
```

---

## ğŸ“š DETAILED DOCUMENTATION

### Pipeline 1: MCMC Training & Postprocessing

**See**: `README_MCMC_TRAINING.md`

**Key Files**:
- `mcmc_convergence.R` - Computes R-hat, ESS, Geweke diagnostics
- `postprocessing_after_mcmc.R` - Transforms MCMC samples for prediction
- `create_species_mapping.R` - Builds TreePPL-compatible species mapping

**What it does**:
- Validates MCMC convergence across multiple chains
- Checks R-hat â‰¤ 1.05, ESS â‰¥ 400, |Geweke| < 2
- Generates trace plots, density plots, diagnostic CSVs
- Thins samples to 500 per model
- Formats JSON for TreePPL prediction input
- Creates species ID mapping matching TreePPL indexing

**Inputs**: TreePPL MCMC output JSONs (3+ chains per model)  
**Outputs**: Prediction input JSONs + convergence diagnostics + species mapping

---

### Pipeline 2: Prediction Stitching

**See**: `README_STITCHING.md` (to be created based on README_STITCHING_PLOTTING.md)

**Key Files**:
- `stitch_simple_n_models_spikeins.R` - For bio/art/comb models
- `stitch_match_models_spikeins.R` - For 6k/8k models (with m parameter)
- `stitch_predictions_fullset.R` - Advanced stitcher with QC

**What it does**:
- Reads NDJSON prediction outputs (pred_out_species_*.json)
- Aggregates predictions across all species
- Validates against count data (fullset version)
- Enforces expected vector lengths
- Generates extensive diagnostics
- Outputs compact RDS for analysis

**Inputs**: TreePPL prediction outputs (NDJSON per species)  
**Outputs**: Stitched RDS files + diagnostic CSVs

---

## ğŸ¯ COMMON WORKFLOWS

### Workflow 1: Standard 5-Model Training & Validation

**Goal**: Train, validate, and prepare 5 models for prediction

```bash
# After TreePPL MCMC training completes:
```

```r
# Step 1: Check all models converged
source("MCMC_TRAINING_PIPELINE/run_mcmc_convergence.R")

# Step 2: Review convergence (all should show "converged")
read.csv("mcmc_check_biospikeins/convergence_summary.csv")
read.csv("mcmc_check_comb/convergence_summary.csv")
read.csv("mcmc_check_6k/convergence_summary.csv")
read.csv("mcmc_check_8k/convergence_summary.csv")
read.csv("mcmc_check_art/convergence_summary.csv")

# Step 3: If all converged, generate prediction inputs
source("MCMC_TRAINING_PIPELINE/run_postprocessing_after_mcmc.R")

# Ready for TreePPL prediction step!
```

---

### Workflow 2: Spike-in Validation Analysis

**Goal**: Compare model performance on 6 known spike-ins

```bash
# After TreePPL predictions complete:
```

```r
# Stitch all 5 models
source("PREDICTION_STITCHING_PIPELINE/run_stitcher_spikeins.r")

# Files created:
# - stitched_pred_spikeins_bio.rds
# - stitched_pred_spikeins_art.rds
# - stitched_pred_spikeins_comb.rds
# - stitched_pred_spikeins_6k.rds
# - stitched_pred_spikeins_8k.rds

# Use plotting pipeline (separate folder) to visualize results
```

---

### Workflow 3: Full Dataset Production Analysis

**Goal**: Process all species with quality control

```bash
# After TreePPL predictions complete:
```

```r
# Step 1: Create species mapping
source("PREDICTION_STITCHING_PIPELINE/create_species_mapping.R")

# Step 2: Review mapping diagnostics
list.files("data/species_map_diagnostics/")
# Check for:
# - runs_ids_not_in_map.csv (unexpected IDs)
# - map_ids_missing_files.csv (missing outputs)

# Step 3: Stitch with quality control
source("PREDICTION_STITCHING_PIPELINE/stitch_predictions_fullset.R")

# Step 4: Review stitching diagnostics
read.csv("output_dir/diag_sweeps.csv")          # Per-sweep decisions
read.csv("output_dir/diag_species_lengths.csv") # Summary by species
read.csv("output_dir/diag_bad_lengths.csv")     # Dropped sweeps

# Step 5: Use stitched_pred_fullset.rds for analysis
```

---

## ğŸ”§ CONFIGURATION

### Quick Configuration Checklist

**Before running MCMC convergence**:
- [ ] Update `chain_paths` in `run_mcmc_convergence.R`
- [ ] Set appropriate `burn_in` (default: 0.5)
- [ ] Set `rhat_thresh` (default: 1.05)
- [ ] Set `ess_thresh` (default: 300)

**Before postprocessing**:
- [ ] Verify convergence passed for all models
- [ ] Update `dir_in` in `run_postprocessing_after_mcmc.R`
- [ ] Update `dir_out` for prediction inputs
- [ ] Update `prior_data` path

**Before stitching spike-ins**:
- [ ] Update `runs_dir` paths in `run_stitcher_spikeins.r`
- [ ] Update `manifest_path` for each model
- [ ] Update `out_rds` paths
- [ ] Verify `expected_len_per_sweep = 15` is correct

**Before stitching fullset**:
- [ ] Update `runs_dir` in `stitch_predictions_fullset.R`
- [ ] Update `counts_path` to your count matrix
- [ ] Set `drop_first_n_rows` to match TreePPL preprocessing
- [ ] Set `drop_spikeins = TRUE/FALSE` to match TreePPL
- [ ] Update `biospikeins` list if needed
- [ ] Choose `length_mode = "strict"` or `"truncate"`

---

## ğŸ“Š KEY OUTPUTS EXPLAINED

### MCMC Convergence Diagnostics

**Location**: `mcmc_check_*/convergence_summary.csv`

**What to look for**:
- âœ… All `verdict` = "converged"
- âœ… `rhat` â‰¤ 1.05 for all parameters
- âœ… `ess` â‰¥ 300 (preferably >400)
- âš ï¸ If any "needs_attention": increase burn-in or run longer

**Example**:
```csv
parameter,rhat,ess,geweke_z,verdict
theta,1.002,1245,-0.34,converged
k_1,1.089,234,1.87,needs_attention  â† FIX THIS
c_1,1.01,678,0.12,converged
```

---

### Prediction Input JSON

**Location**: Output from postprocessing (e.g., `pred_in_bio_mcmc.json`)

**Structure**:
```json
{
  "k_bio_dist": [2.3, 1.8, 2.1, ...],     // 500 samples
  "c_dist": [[0.1, ...], [0.11, ...], ...], // 500 Ã— 15
  "theta_list": [0.45, 0.48, ...],        // 500 samples
  "weights": [0.002, 0.002, ...],         // All equal
  // ... prior parameters
}
```

**Use**: Input to TreePPL prediction step

---

### Species Mapping

**Location**: `data/species_map.csv`

**Structure**:
```csv
species_id,species,canonical_index
1,Acarina_cluster1,1
2,Aleyrodidae_cluster1,2
5,Apidae_cluster1,5
```

**Note**: Gaps in species_id (e.g., 3, 4 missing) are normal if zero-count species were dropped

**Diagnostics**: Check `data/species_map_diagnostics/` for validation

---

### Stitched Predictions

**Location**: `stitched_pred_spikeins_*.rds` or `stitched_pred_fullset.rds`

**Structure**:
```r
list(
  n               = numeric(),  # All predictions concatenated
  offsets         = integer(),  # Start index per sweep
  lengths         = integer(),  # Length per sweep
  species_indices = integer(),  # Species ID per sweep
  m               = integer(),  # Match parameter (6k/8k only)
  normconst       = numeric()   # Normalization constant
)
```

**Use**: Input for analysis and plotting

---

## ğŸ› COMMON ISSUES & SOLUTIONS

### Issue: MCMC hasn't converged

**Symptoms**:
- R-hat > 1.05
- ESS < 300
- Verdict = "needs_attention"

**Solutions**:
1. Increase burn-in (try 0.6 or 0.7)
2. Run MCMC for more iterations
3. Check trace plots for mixing issues
4. Verify initial values are reasonable

---

### Issue: Species mapping mismatches

**Symptoms**:
- Diagnostic CSVs show unexpected IDs
- `runs_ids_not_in_map.csv` has many entries
- `map_ids_missing_files.csv` has many entries

**Solutions**:
1. Verify `drop_first_n_rows` matches TreePPL exactly
2. Verify `drop_spikeins` matches TreePPL exactly
3. Check that `biospikeins` list is complete
4. Ensure counts file is the one TreePPL used

---

### Issue: Stitching drops many sweeps

**Symptoms**:
- `diag_bad_lengths.csv` has many rows
- Many sweeps show "drop" decision

**Solutions**:
1. Check `expected_len_per_sweep` is correct
2. Use `length_mode = "truncate"` instead of `"strict"`
3. Review prediction outputs - are they malformed?
4. Check TreePPL prediction logs for errors

---

### Issue: Wrong abundances in results

**Symptoms**:
- Predictions don't match spike-in known values
- Results seem shifted or misaligned

**Solutions**:
1. Regenerate species mapping
2. Verify TreePPL preprocessing steps
3. Check manifest.json has correct species IDs
4. Ensure prediction outputs are from correct model

---

## ğŸ’¡ BEST PRACTICES

### MCMC Training
âœ… **DO**:
- Always run 3+ chains for R-hat calculation
- Check convergence before proceeding
- Save all diagnostic plots
- Document settings used

âŒ **DON'T**:
- Skip convergence checks
- Use only 1-2 chains
- Delete raw MCMC outputs
- Ignore "needs_attention" warnings

### Prediction Processing
âœ… **DO**:
- Create species mapping before stitching
- Validate mapping diagnostics thoroughly
- Review stitching diagnostics
- Keep preprocessing consistent with TreePPL

âŒ **DON'T**:
- Skip diagnostic review
- Change preprocessing mid-project
- Ignore length mismatches
- Mix data from different runs

### General
âœ… **DO**:
- Version control your scripts
- Document directory paths used
- Keep README files updated
- Use descriptive output directory names

âŒ **DON'T**:
- Hardcode temporary paths
- Skip documentation
- Mix different TreePPL runs
- Overwrite important outputs

---

## ğŸ“¦ FILE DEPENDENCIES

### MCMC Training Pipeline

```
run_mcmc_convergence.R
  â””â”€â”€ requires: mcmc_convergence.R

run_postprocessing_after_mcmc.R
  â””â”€â”€ requires: postprocessing_after_mcmc.R
  â””â”€â”€ requires: jsonlite package

create_species_mapping.R
  â””â”€â”€ standalone (no dependencies)
```

### Prediction Stitching Pipeline

```
run_stitcher_spikeins.r
  â”œâ”€â”€ requires: stitch_match_models_spikeins.R (for 6k, 8k)
  â””â”€â”€ requires: stitch_simple_n_models_spikeins.R (for bio, art, comb)

stitch_predictions_fullset.R
  â”œâ”€â”€ requires: data/species_map.csv
  â”œâ”€â”€ requires: counts CSV file
  â””â”€â”€ standalone otherwise
```

---

## ğŸ”¢ PIPELINE STATISTICS

### Processing Scale
- **Models**: 5 configurations (bio, art, comb, 6k, 8k)
- **MCMC chains**: 3 per model (15 total)
- **Parameters tracked**: ~20-30 per model
- **Samples per chain**: Varies (typically 5,000-10,000)
- **Thinned samples**: 500 per model (for prediction)
- **Species processed**: Configurable (6 for spike-ins, 100s for fullset)
- **Sweeps per species**: Varies (prediction-dependent)

### Output Sizes (typical)
- Convergence diagnostics: ~50 KB CSV + ~2 MB plots per model
- Prediction input JSON: ~1-5 MB per model
- Stitched RDS: ~5-50 MB (depending on species count)
- Diagnostic CSVs: ~10-100 KB total

---

## ğŸ†˜ GETTING HELP

### Documentation Hierarchy

1. **This README** - Overall workflow and quick start
2. **README_MCMC_TRAINING.md** - Detailed MCMC pipeline documentation
3. **README_STITCHING.md** - Detailed stitching pipeline documentation
4. **Script comments** - Function-level documentation in each file

### Debugging Strategy

1. **Check file paths** - Most errors are path-related
2. **Review diagnostics** - CSVs contain detailed error info
3. **Inspect intermediate outputs** - Don't skip validation steps
4. **Check TreePPL logs** - Upstream errors affect downstream
5. **Verify preprocessing** - Consistency is critical

### Support Resources

- TreePPL documentation: For MCMC and prediction setup
- R CODA package docs: For convergence diagnostic interpretation
- Script header comments: For function-specific guidance

---

## ğŸ“… TYPICAL TIMELINE

**For 5 models with 3 chains each**:

| Stage | Time | Notes |
|-------|------|-------|
| TreePPL MCMC training | Hours-days | Depends on model complexity |
| Convergence checking | 5-10 min | Automated |
| Review diagnostics | 10-20 min | Manual inspection |
| Postprocessing | 1-2 min | Automated |
| TreePPL predictions | Minutes-hours | Depends on data size |
| Species mapping | 1-2 min | One-time setup |
| Stitching | 2-5 min | Depends on species count |
| Review stitching diagnostics | 5-10 min | Manual inspection |

**Total hands-on time**: ~30-60 minutes (plus TreePPL compute time)

---

## ğŸ“ LEARNING PATH

### For New Users

**Week 1**: MCMC Training Pipeline
1. Read `README_MCMC_TRAINING.md`
2. Run convergence checks on example data
3. Practice interpreting R-hat, ESS values
4. Review trace plots

**Week 2**: Prediction Processing
1. Read `README_STITCHING.md`
2. Create species mapping
3. Stitch spike-in validation data
4. Review diagnostics

**Week 3**: Full Workflow
1. Run complete pipeline end-to-end
2. Troubleshoot any issues
3. Customize for your data

**Week 4**: Advanced Topics
1. Tune convergence parameters
2. Use fullset stitcher with QC
3. Interpret complex diagnostic outputs
4. Optimize for your specific use case

---

## ğŸ”„ VERSION HISTORY

**Current Version**: v1.0 (February 2026)
- Complete MCMC training pipeline
- Spike-in validation stitching
- Full dataset stitching with QC
- Species mapping utility
- Comprehensive documentation

**Recent Updates**:
- âœ… Fixed plotting script (merged complete functions)
- âœ… Added clear file naming (`_spikeins` suffix)
- âœ… Created species mapping validation
- âœ… Added extensive diagnostics
- âœ… Separated plotting to its own folder

---

## ğŸ“ FILE CHECKLIST

Before running analysis, ensure you have:

**MCMC Training Pipeline** (5 files):
- [ ] `mcmc_convergence.R`
- [ ] `run_mcmc_convergence.R`
- [ ] `postprocessing_after_mcmc.R`
- [ ] `run_postprocessing_after_mcmc.R`
- [ ] `create_species_mapping.R`

**Prediction Stitching Pipeline** (3-4 files):
- [ ] `stitch_simple_n_models_spikeins.R`
- [ ] `stitch_match_models_spikeins.R`
- [ ] `run_stitcher_spikeins.r`
- [ ] `stitch_predictions_fullset.R` (optional, for fullset)

**Data Files**:
- [ ] Count matrix CSV
- [ ] Prior parameters JSON
- [ ] Manifest JSON files (per model)

**TreePPL Outputs**:
- [ ] MCMC chain JSONs (3+ per model)
- [ ] Prediction output JSONs (per species)

---

## ğŸ¯ SUCCESS CRITERIA

Your pipeline is working correctly if:

âœ… **After convergence checking**:
- All parameters show "converged" verdict
- R-hat values â‰¤ 1.05
- ESS values â‰¥ 400
- Trace plots show good mixing

âœ… **After postprocessing**:
- 5 prediction input JSON files created
- Files are valid JSON (test with `fromJSON()`)
- Each contains 500 samples

âœ… **After species mapping**:
- `species_map.csv` created
- Diagnostic CSVs show minimal mismatches
- IDs align with TreePPL outputs

âœ… **After stitching**:
- RDS files contain expected species
- Diagnostic CSVs show acceptable drop rates
- Data structure is correct (test with `str()`)

---

## ğŸš¦ FINAL CHECKLIST

**Before running your analysis**:
- [ ] Read this README completely
- [ ] Read pipeline-specific READMEs
- [ ] Update all file paths in scripts
- [ ] Install all required R packages
- [ ] Verify TreePPL outputs are complete
- [ ] Create backup of original data
- [ ] Set up output directories
- [ ] Document your configuration

